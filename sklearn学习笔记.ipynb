{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.load('F:/dataset/feature_matrix_save.npy')\n",
    "class_list = np.load('F:/dataset/class_result_save.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31622777 0.31622777 0.31622777 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[ 7.38617327  4.24099011 14.10673598 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]\n",
      " [-0.1353881  -0.15381829 -0.07088812 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]\n",
      " [-0.1353881  -0.15381829 -0.07088812 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]\n",
      " ...\n",
      " [-0.1353881  -0.15381829 -0.07088812 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]\n",
      " [-0.1353881  -0.15381829 -0.07088812 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]\n",
      " [-0.1353881  -0.15381829 -0.07088812 ... -0.0316386  -0.0316386\n",
      "  -0.0316386 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "##归一化\n",
    "normalized_x=preprocessing.normalize(feature_matrix)\n",
    "print(normalized_x)\n",
    "##标准化\n",
    "standardized_x=preprocessing.scale(feature_matrix)\n",
    "print(standardized_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择\n",
    "\n",
    "在解决一个实际问题的过程中，选择合适的特征或者构建特征的能力特别重要。这成为特征选择或者特征工程。\n",
    "特征选择时一个很需要创造力的过程，更多的依赖于直觉和专业知识，并且有很多现成的算法来进行特征的选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3992)\n",
      "************************************************\n",
      "(1000, 76)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "model = RandomTreesEmbedding()\n",
    "print(feature_matrix.shape) # 原特征矩阵规模\n",
    "feature_matrix =(model.fit(feature_matrix, class_list)).transform(feature_matrix)\n",
    "print(\"************************************************\")\n",
    "print(feature_matrix.shape) # 特征选择后 特征矩阵的规模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取\n",
    "\n",
    "用TFIDF算法来计算特征词的权重值是表示当一个词在这篇文档中出现的频率越高，同时在其他文档中出现的次数越少，则表明该词对于表示这篇文档的区分能力越强，所以其权重值就应该越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "feature_matrix = tfidf_transformer.fit_transform(feature_matrix).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯(Naive Bayes)\n",
    "朴素贝叶斯是一个很著名的机器学习算法，主要是根据训练样本的特征来计算各个类别的概率，在多分类问题上用的比较多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.08      0.15       500\n",
      "          1       0.52      1.00      0.68       500\n",
      "\n",
      "avg / total       0.76      0.54      0.42      1000\n",
      "\n",
      "[[ 40 460]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 构建朴素贝叶斯模型\n",
    "model = GaussianNB()\n",
    "model.fit(feature_matrix, class_list)\n",
    "print(model)\n",
    "# 使用测试集进行测试(此处将训练集做测试集)\n",
    "expected = class_list\n",
    "predicted = model.predict(feature_matrix)\n",
    "# 输出测试效果\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k近邻(k-Nearest Neighbours)\n",
    "k近邻算法常常被用作是分类算法一部分，比如可以用它来评估特征，在特征选择上我们可以用到它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.99      0.68       500\n",
      "          1       0.88      0.06      0.11       500\n",
      "\n",
      "avg / total       0.70      0.53      0.39      1000\n",
      "\n",
      "[[496   4]\n",
      " [470  30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 构建knn模型\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(feature_matrix, class_list)\n",
    "print(model)\n",
    "# 使用测试集进行测试(此处将训练集做测试集)\n",
    "expected = class_list\n",
    "predicted = model.predict(feature_matrix)\n",
    "# 输出测试效果\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树(Decision Tree)\n",
    "分类与回归树(Classification and Regression Trees ,CART)算法常用于特征含有类别信息的分类或者回归问题，这种方法非常适用于多分类情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.09      0.17       500\n",
      "          1       0.52      0.99      0.69       500\n",
      "\n",
      "avg / total       0.73      0.54      0.43      1000\n",
      "\n",
      "[[ 46 454]\n",
      " [  3 497]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 构建决策数模型\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(feature_matrix, class_list)\n",
    "print(model)\n",
    "# 使用测试集进行测试(此处将训练集做测试集)\n",
    "expected = class_list\n",
    "predicted = model.predict(feature_matrix)\n",
    "# 输出测试效果\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
