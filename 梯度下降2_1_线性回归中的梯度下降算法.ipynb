{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(66)   #seed 函数保留种子，以便重新运行时，随机数不变\n",
    "x=2*np.random.random(size=100)\n",
    "y=x*3.+4.+np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30857516, 0.26739912, 0.72537093, 1.35821775, 0.38890011,\n",
       "       0.50242077, 1.51683278, 1.11523718, 1.02960584, 0.93559972,\n",
       "       0.17435201, 1.65819088, 0.59728112, 0.06269178, 1.35601151,\n",
       "       1.80697807, 1.02890237, 1.07821095, 1.32865503, 1.26811351,\n",
       "       0.70683894, 0.05328503, 0.33057968, 1.75863798, 0.13564091,\n",
       "       0.7381716 , 0.23100117, 0.19258829, 0.1675394 , 0.17385405,\n",
       "       0.04451169, 1.54208544, 0.09842525, 0.93044648, 1.88246613,\n",
       "       0.43302461, 0.72263693, 0.06263726, 0.60808907, 0.37653535,\n",
       "       0.25231926, 0.82843367, 1.8893422 , 0.07668703, 1.91408018,\n",
       "       0.25263162, 0.1558952 , 0.33216602, 1.9095358 , 0.53612251,\n",
       "       0.20108188, 1.81555236, 1.10674936, 1.49738524, 0.21344696,\n",
       "       1.57282878, 1.31755546, 0.72391313, 1.29970958, 0.4610867 ,\n",
       "       1.43371702, 0.53224281, 1.24559233, 1.6286177 , 0.07875057,\n",
       "       1.18252429, 0.64277566, 1.02283256, 1.00681168, 0.62212791,\n",
       "       1.81596165, 0.54830525, 1.63735236, 1.10556513, 1.29417965,\n",
       "       1.40574876, 0.82361162, 1.79669592, 0.12821663, 1.32893547,\n",
       "       0.6337655 , 1.40747386, 1.54074928, 0.83600785, 0.1784633 ,\n",
       "       0.46703775, 1.51903741, 0.93836429, 0.40590744, 1.3921877 ,\n",
       "       1.81989727, 0.11646456, 1.57717453, 0.79136753, 1.63025106,\n",
       "       1.13275892, 0.79906514, 1.39780184, 1.17225983, 1.09652128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11725437,  5.28827477,  5.77892206,  7.77341059,  4.71472072,\n",
       "        7.65299045,  8.22513611,  8.2832634 ,  7.64683806,  7.19033974,\n",
       "        4.49236113,  7.35580306,  6.23169071,  4.6221855 ,  6.65892661,\n",
       "        9.83731115,  5.36421206,  6.97515741,  9.02896846,  9.45800369,\n",
       "        5.20374744,  2.94481497,  3.75345729, 11.07519777,  4.82581679,\n",
       "        4.91175576,  5.52983867,  4.63220263,  4.40803951,  4.18434377,\n",
       "        2.40098633,  8.41233406,  4.39638416,  7.81951197,  9.39617717,\n",
       "        5.18186303,  6.98524303,  4.07873908,  5.71574187,  4.70521653,\n",
       "        5.55633383,  5.87172825, 10.40179711,  5.06170612,  8.40267038,\n",
       "        5.4004198 ,  4.3565488 ,  4.40660224, 10.54258565,  5.86707894,\n",
       "        6.39029284, 10.04668138,  7.52198287,  9.23110931,  4.16564275,\n",
       "        8.67875716,  7.63690732,  8.25198409,  9.0920277 ,  4.51372108,\n",
       "       10.09449316,  6.10935732,  7.68209042,  8.5157148 ,  4.65097121,\n",
       "        7.30581352,  6.80919945,  9.00530477,  6.51934472,  3.87531532,\n",
       "        7.91014988,  5.25839249,  9.69770437,  7.03427232,  6.55011175,\n",
       "        7.0927464 ,  4.64148442,  9.26646291,  5.27378192,  7.55862058,\n",
       "        6.6123652 ,  9.10269745,  9.61631007,  6.34347556,  4.2339249 ,\n",
       "        7.0197294 ,  8.5282946 ,  8.5597436 ,  5.01648182,  8.39126075,\n",
       "        9.92900422,  3.80129404,  8.41142006,  5.36733384,  9.2372697 ,\n",
       "       10.16692475,  6.93070696,  8.54598061,  8.19445535,  7.12479327])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x88662b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGgtJREFUeJzt3X2sZVV5x/Hf48wIF0odKGMLV8eBxEBEhIGbxjLGCmhBsDLFRDHaiNJM7IvF1tIMoana2DAJaaVNmzaUWDUSxAKdotYidTCmKJg7DDAgogiCXKyMwmjREQd4+sfZF86cOS/7Ze191lrn+0kmc+95ueeZfc88e+1nPWsdc3cBAPL0gmkHAABoD0keADJGkgeAjJHkASBjJHkAyBhJHgAyRpIHgIyR5AEgYyR5AMjYyi5f7PDDD/d169Z1+ZIAkLzt27f/0N3X1Hlup0l+3bp1Wlxc7PIlASB5ZvZQ3edSrgGAjJHkASBjJHkAyBhJHgAyRpIHgIyR5AEgY522UAJADLbuWNJlN96nR3fv0ZGr53TRGcdo4/r5aYfVCpI8gJmydceSLr5+p/bsfUaStLR7jy6+fqckZZnoKdcAmCmX3Xjfcwl+2Z69z+iyG++bUkTtIskDmCmP7t5T6fbUkeQBzJQjV89Vuj11JHkAM+WiM47R3KoV+9w2t2qFLjrjmClF1C4mXgHMlOXJVbprACBTG9fPZ5vUB1GuAYCMkeQBIGMkeQDIGEkeADLGxCsABBbT3jgkeQAIKLa9cSjXAEBAse2Nw0geAAJYLtEsRbY3DkkeABoaLNEMM629cSjXAEBDw0o0/aa5Nw4jeQBoaFwpZp7uGgBI25Gr54bW4udXz+mWzadNIaLnUa4BWrZ1x5I2bNmmozZ/Xhu2bNPWHUvTDgmBxbx9MSN5oEWx9UyjHTFvX0ySB1o0rmc6hgRQVkwrOGMV6/bFE5O8mX1M0pskPeburyxuO0zSNZLWSfqupLe6+xPthQmkKYfPE53Vq5FcTmxlavIfl3TmwG2bJX3J3V8u6UvF9wAG5PB5orGt4OzC8oltafceuZ4/saU4nzIxybv7VyQ9PnDzOZI+UXz9CUkbA8cFZCHmCbmycrgaqSqnE1vd7ppfdffvS1Lx94vDhQTkY+P6eV167vGaXz0nU6+l7tJzj0/qsj+Hq5GqRp3ARm1ZELPWJ17NbJOkTZK0du3atl8OiE6sE3JlXXTGMfst2U/taqSqUX3vpl4pJ6XfZ92R/A/M7AhJKv5+bNQD3f0Kd19w94U1a9bUfDkA05LD1UhVpx47PFe5lFzJpu5I/gZJ75K0pfj7P4JFBCA6qV+NVLF1x5Ku2z56gjW1uYiJI3kzu1rS1yQdY2aPmNkF6iX3N5jZtyW9ofgeAJI3abOx1OYiJo7k3f3tI+46PXAsADBUlz3r40bqKc5FsHcNgKh13bM+aqS+wizJuQiSPIBO1N2oreue9VFrG/7mrSckl+Al9q4B0IEmWyN0vRgr5s3G6iDJA2hdk43aRvWstzkBmlM3EeUaIFEp7VPfZDSew9YQ08RIHkhQajtDNhmN51Y+6RpJHkhQavvUN90aIfbySczbEpPkgQSltjNkzqPx2K+qSPJAgqYxGdlU7KPxumK/qiLJAwmKdWfINsoWXZZC6rxW7FdVJHkgQTGWP9ooW3RZCqn7WrFfVZHkgUTFVv5oo2zRZSmk7mvFelW1jCQPYB91yyNtlC26LIXUfa0Yr6r6keSBjDStXzcpj7RRtuiyFNK0lz+WpD6IFa9AJkbt1vgXW3eWXhnbZDOwNlamdrnaNdeVtYzkgRFiXuAyzKgEfdWtD8uL7yeNzJuUR9ooW3RZCom97FKXufvkRwWysLDgi4uLnb0eUNdg2ULqjepi3k/8qM2fV9n/zfOr53TL5tP2u33Dlm1DSxajHo9umNl2d1+o81zKNcAQXe9hHkKVOvWokXmuJYtZRpIHhoh9gcswwxK0jXjsqBPCxvXzuvTc4zW/ek6m3gg+5qsXTEZNHhgi9gUuwwyrKZ967Bpdt32pUg93zJ0iqI4kDwwR+wKXUYYl6IWXHZbdZCLKI8kDQ+TUacHIfLaR5IERSI7tS61NNUUkeQBTEfs+7LmguwbAVKTYppoiRvKYCZQFygl5nCb9rBTbVFNEkkf2KAuUE/I4lflZZdtUOUE3Q7kG2aMsUE7I41TmZ5VZXTtq07Vxm6xhXyR5ZI+yQDkhj9Oo5yzt3vPcbpiSdOm5x2v13Krn7j9w1b4pKeUT9NYdS6V3/2wTSR7ZG7VKNebVq9Ow+qBVQ2+vc5zGPad/RL740ON66ulnn7vviZ/t3WeknuoJOqYrEJI8ssemW5Nt3bGkJ3/+9H63r1phtY7TsGM+aM/eZ3T1bd8bO1JP9QQd0xUISR7Zm8amW7Fcqpd12Y33ae+z+29UfPALV9Y6ToPHfJRnRmx1vjxST/UEHdMVCN01aE1MXRFdrl5NsZtnVPL58Z69QX7+CrOhCX3U7csj9VS3l4hpgzuSPFqRYqILZdylev+/PaaTYOikNPj7H5bI51at0FtOnp+4S2aK20vEtMEd5Rq0IqaaZNfKXKrHNDEnhS+LDPv9S72Re3/J7CMbj89y//qY9uVnJI9WxFST7FqZUXHZ0X5XQpdFRv2en3XXg1vO3u+1U0/qw8Ty7yLJoxUx1SS7VuZSPcaTYMikNMu//9g0KteY2Z+Y2T1mdreZXW1mB4YKDGlLtSsihDKX6qm2BpY1y7//2NQeyZvZvKQ/lvQKd99jZp+RdJ6kjweKDQlLtSsilEmj4pgm5tow67//mDQt16yUNGdmeyUdJOnR5iEhF7HUJGM0C0kw9d9/TN1PTZiPWIxQ6slmF0r6a0l7JH3R3d8x5DGbJG2SpLVr15780EMP1X49AOjCYAuo1LvSmlaHjJltd/eFOs+tXZM3s0MlnSPpKElHSjrYzN45+Dh3v8LdF9x9Yc2aNXVfDgA6k1MLcJNyzeslPejuuyTJzK6XdIqkT4UIDAghl0tudCvG7qe6miT5hyW92swOUq9cc7qkxSBRAQHM8qrbcTjxTZZTC2jtco273ybpWkm3S9pZ/KwrAsUFNJbTJXcosa20jVVOLaCNumvc/YOSPhgoFjTECG1fIS65YzqmIWKJbaVtrHLqfmLFayYoTeyv6SV3TMe0TizDTgo51ZrblnoL6DI2KMsEpYn9Nb3kjumYVo1lWFnm/dfcoVGbu6dYa0Y5jOQzwQhtf00vuese0zZKPFVjGbUL5LBlManWmlEOST4TOXUDhNTkkrvOMW2rxFM1lkknohVmetY96VozyqFck4mcugFiUeeYtlXiqRrLpJP78pa/t2w+jQSfOZJ8JmL6kIJc1DmmbZXNqsYy6YO0Z/0Kb5ZQrslILt0AMal6TNssm1WJZflxH7rhHu0e+JzWHK7wYmptjR0jeSCgOiWerTuWtGHLNh21+fPasGVbsIVJG9fP644P/pYuf9uJWV3hsaCrGkbyQEBVO3q66MXP7QqPBV3VkOSBwKokVRJWdbQLV0OSR/Zirt+SsKqjXbgaavLIWpf12zq19dw/67UNtAtXQ5JH1rramqDuySTGhNXWRHAotAtXQ7kGWeuqHDLqZPKBz9wpafQkamy7Hca0Kds4uU0mt4kkn6iY68zLYoixq/rtqJPGM+4Tk2RMCYuJ4PxQrklQCn3CscTYdjlkubQxZN+v56S0GygTwfkhyScopi1wR6kTYxu14Dbrt/0nsklSSZJMBOeHck2CUhhtVY2xzVpwW+WQUdv5DpNKkrzojGP2+T1I058IRjOM5BM0jdFW1VF21RhTuDoZVPakmlKSpHMlP4zkE9T1aKvOKLtqjClcnQwaNam7em6VDj5gZdST4uPENBGM5kjyCeq67a5Ox0XVGFNcxTjqRPahNx9HkkQ0SPKJ6nK0VXeUXSXGFGvBsfW4A8OQ5DFRF6PsVBNmiqWNGNYvoDskeUx06rFrdNWtD+/TC97GKDvFhJmaVFa0IhySPMbaumNJ121f2ifBm6S3nExCjk2ZETorWmcPSR5jDUsKLunmb+6aTkAdSLGcUXaEnmIXE5qhTx5jzVpSiGU7hqrKrjNgRevsIcljrFlLCikuypLKn4xj3NoY7SLJ94l9H+1pmLWkkOqVS9mTMStaZw81+QJdB8PF0NrYZY08xUVZUrV1BnQxzRaSfIGug9GmmRS6PvmmuChLiuNkjDiR5AupXqbnruuTb8rJkhE6hiHJF1K9TA8pxtbBaZx8SZbICROvhVmbYBwUa+vgrHX3AKGR5Au5dh2U7RiKtXVw1k++QFOUa/rkdpleZdIy1jmJlGvkQAwaJXkzWy3pSkmvVG+1+3vc/WshAkNzVSYtY56TyO3kC3Spabnm7yT9l7sfK+kESfc2DwmhVBmdUxYB8lR7JG9mvyzptZLOlyR3/4WkX4QJCyFUGZ1TFgHy1KRcc7SkXZL+1cxOkLRd0oXu/tMgkaGxqgt7KIsA+WlSrlkp6SRJ/+Tu6yX9VNLmwQeZ2SYzWzSzxV278t2eNkbLHUOHHrTqudsOWJlWQxX7CQHNNPkf/4ikR9z9tuL7a9VL+vtw9yvcfcHdF9asWdPg5VDXz/c++9zXu/fsjaL/vYxYe/eBlNRO8u7+v5K+Z2bL1/6nS/pGkKgQzDT735uOwmPt3QdS0rRP/n2SrjKzF0p6QNK7m4eEkKr2v4fa2iDExmKx9u4DKWlUoHX3O4pSzKvcfaO7PxEqMIRRZVuAkOWREKNwtjQAmktrFg6VVel/D1keCTEKp3cfaI5tDTJXpf89ZHkkxApaeveB5kjyFcS4FW8ZZfvfQ25tEOrDN+jdB5ohyU+wnNiXdu+RqbdBj5TnxwOG/FQkRuFAHEjyYwx2iPjA/bl9PGDoxMwoHJg+kvwYwyYiB+XWzkdiBvJCkh+jTAJ/0dyqiY/BZLHOd8QaF1AWSX6MUROR/cw6CiZjIRZOzVJcQBVZ98k3XVY/rE970BM/28teKg3Fun1BrHEBVWQ7kg8xCuufiBw3ok9ldBdr6SHW7QtijQuoItuRfKhR2Mb187pl82m6/G0njhzVtzm6C7XVblc7OtaJN9btC2KNC6gi2yQfehS2vDd71ddrIra9ZCapG2+s2xfEGhdQRbZJvo1R2Mb185rvcHQX214yk9SNd/kEOr96TiZpfvWcLj33+KmXkmKNC6gi6Zr8uBpzyNWb/dr6ucPEtpfMJE3ijbU/P9a4gLKSTfKTJlbbWlbf9nL9/hPXC8z0jA+us53uXjLjdHEiAVBNskl+XGlgOeG2NQpr6+cOnriGJfiY95Lp8ioHQDnJJvkc29tGbaOwwkzPuke/lwybkgHxSTbJ51gaGHWCetZdD245u+No6hl2Iom1Px+YBcl21+TY3pZjX3ZX/fkAhks2yZdtbwu1mKgLOZ642BoAmK5kyzXS5BpzahtM5VjTznHuBEhJ0kl+kjIdONPU/6lTK4p2yfkMEnu/HOdOgJQkW66RJpdiYh5F9teqpefbJXOrWedYggJSktxIvspnrpYdRU6j+2Pcp07FdLXRVJMSFF05QHNJJfmqn7laZnHOtOr2k64mYrjaCKVOf35q8ylArJIq11T9zNUyHTjT6v6YVJOe9Zo1XTlAGEmN5MuMbgeT46hRZH/Zp+5rNTHsKmPZpJr1LJQxYp5PAVKSVJKf9JmrZSf0BksBo16rTYOfOlW2u2ZWyhh05QBhmA/ZBKstCwsLvri4WPv5w5Lz8uTroQetkrv04z17J45uT/zwF7V7z96RrzO3akWwfcNDj7o3bNk2NPnNr57TLZtPaxJqVIb9rkP+XoCUmNl2d1+o89ykRvKjOjUklRrdbt2xpA9/9p6xCT5kn3obo+5ZKWPkuDAMmIakkrw0vMa+Ycu2iYueypRoQo+G21iMNUtlDD6wA2guqe6aUcqMbst05oReoNPGqJvFRQCqyCLJl9m9cVJifYEFDWm/1y9zexl87iiAKpIr1wxTZtHTpM6cZ13Bu1Ta+qQkyhgAysoiyZeZpBvXl76sf7FNiAk/Jg8BTFtSLZRSs5bESQugls2tWkHrHoBoNGmhTKom3/RThjaun9ctm0/TuPL7CjOW0wPIRuMkb2YrzGyHmX0uREDjhNrPZNTEp+n5LX8H5daHDmA2hBjJXyjp3gA/Z6JQLYnD2hBN0jtevVbzGX7OKoDZ1SjJm9lLJJ0t6cow4YwXqiVxWBviR992oj6y8Xj60AFkpWl3zeWS/lzSIaMeYGabJG2SpLVr1zZ6sZAtiaPaEOmIed4s7HYJ5K52kjezN0l6zN23m9nrRj3O3a+QdIXU666p+3pSdwmYPvTZ2e0SyF2TkfwGSW82s7MkHSjpl83sU+7+zjChDVcmATMCbS72D0EHUE7tJO/uF0u6WJKKkfyftZ3gy4htBJrqCWdWdrsEcpdUn3wZMX1sXNO+/mlqY98dAN0LkuTd/cvu/qYQP6upmEagMZ1wqqLLCMhDdiP5mEagMZ1wqmK3SyAPWWxQ1q+tnR/rSP0DPugyAtKX3Ug+phEoJQ8A05bdSF6KZwTKwioA05Zlko9JLCccALMpu3INAOB5JHkAyBhJHgAyRpIHgIyR5AEgYyR5AMgYLZSBpbrrJIA8keQDim2bYwCgXBNQyrtOAsgTST6glHedBJCnpMo1sde7U991EkB+khnJp/ApS+w6CSA2yST5FOrdMW1zDABSQuWaVOrd7DoJICbJjORj+lg/AEhFMkmeejcAVJdMuYZPWQKA6pJJ8hL1bgCoKplyDQCgOpI8AGSMJA8AGSPJA0DGSPIAkLEkumti35gMAGIVfZLngzgAoL7oyzUpbEwGALGKPsmnsjEZAMQo+iTPxmQAUF/0SZ6NyQCgvugnXtmYDADqiz7JS2xMBgB11S7XmNlLzexmM7vXzO4xswtDBgYAaK7JSP5pSR9w99vN7BBJ283sJnf/RqDYAAAN1R7Ju/v33f324uv/k3SvJGoqABCRIN01ZrZO0npJt4X4eQCAMBoneTP7JUnXSXq/u/9kyP2bzGzRzBZ37drV9OUAABWYu9d/stkqSZ+TdKO7/22Jx++S9NCEhx0u6Ye1g+pG7DESX3Oxx0h8zcUeY398L3P3NXV+SO0kb2Ym6ROSHnf399f6IcN/7qK7L4T6eW2IPUbiay72GImvudhjDBVfk3LNBkm/K+k0M7uj+HNW04AAAOHUbqF09/+RZAFjAQAEFuPeNVdMO4ASYo+R+JqLPUbiay72GIPE12jiFQAQtxhH8gCAQDpN8mZ2ppndZ2b3m9nmIfcfYGbXFPffViyyWr7v4uL2+8zsjCnF96dm9g0zu8vMvmRmL+u775m+CegbphTf+Wa2qy+O3+u7711m9u3iz7vaiK9kjB/ti+9bZra7774ujuHHzOwxM7t7xP1mZn9fxH+XmZ3Ud1/rx7BEfO8o4rrLzL5qZif03fddM9tZHL/FKcX3OjP7cd/v8S/77hv73ugovov6Yru7eM8dVtzX+vErXmfivl9B34fu3skfSSskfUfS0ZJeKOlOSa8YeMwfSPrn4uvzJF1TfP2K4vEHSDqq+DkrphDfqZIOKr7+/eX4iu+fjOD4nS/pH4Y89zBJDxR/H1p8feg0Yhx4/PskfayrY1i8xmslnSTp7hH3nyXpC+o1Fbxa0m0dH8NJ8Z2y/LqS3rgcX/H9dyUdPuXj9zpJn2v63mgrvoHH/rakbV0ev+J1jpB0UvH1IZK+NeT/crD3YZcj+V+XdL+7P+Duv5D0aUnnDDzmHPV67yXpWkmnm5kVt3/a3Z9y9wcl3V/8vE7jc/eb3f1nxbe3SnpJ4BgaxTfGGZJucvfH3f0JSTdJOjOCGN8u6eoW4hjJ3b8i6fExDzlH0ie951ZJq83sCHV0DCfF5+5fLV5f6v49WOb4jdLk/Vtaxfg6f/9Jpff9CvY+7DLJz0v6Xt/3j2j/f9hzj3H3pyX9WNKvlHxuF/H1u0C9M+2yA623fcOtZrYxcGxV4ntLcXl3rZm9tOJzu4pRRanrKEnb+m5u+xiWMerf0NUxrGLwPeiSvmhm281s05RikqTfMLM7zewLZnZccVtUx8/MDlIvOV7Xd3Pnx89G7/sV7H3Y5YeGDOupH2ztGfWYMs9tqvRrmNk7JS1I+s2+m9e6+6NmdrSkbWa2092/03F8n5V0tbs/ZWbvVe+q6LSSzw2hyuucJ+lad3+m77a2j2EZ03wPlmZmp6qX5F/Td/OG4vi9WNJNZvbNYmTbpdvVW4L/pPUWR26V9HJFdvzUK9Xc4u79o/5Oj5+N3/cr2Puwy5H8I5Je2vf9SyQ9OuoxZrZS0ovUu/Qq89wu4pOZvV7SJZLe7O5PLd/u7o8Wfz8g6cvqnZ07jc/df9QX079IOrnsc7uKsc95GrhU7uAYljHq39DVMZzIzF4l6UpJ57j7j5Zv7zt+j0n6d4UvaU7k7j9x9yeLr/9T0iozO1wRHb/CuPdf68fPevt+XSfpKne/fshDwr0P255k6JtIWKneJMFRen7i5biBx/yh9p14/Uzx9XHad+L1AYWfeC0T33r1Jo9ePnD7oZIOKL4+XNK3FXhSqWR8R/R9/TuSbvXnJ2seLOI8tPj6sGn8jovHHaPeJJd1eQz7XmudRk8cnq19J7y+3uUxLBHfWvXmpE4ZuP1gSYf0ff1VSWdOIb5fW/69qpckHy6OZan3RtvxFfcvDx4PntLxM0mflHT5mMcEex8G/wdM+Medpd5M8nckXVLc9lfqjYol6UBJ/1a8ib8u6ei+515SPO8+SW+cUnz/LekHku4o/txQ3H6KpJ3FG3enpAumFN+lku4p4rhZ0rF9z31PcVzvl/Tuaf2Oi+8/JGnLwPO6OoZXS/q+pL3qjYoukPReSe8t7jdJ/1jEv1PSQpfHsER8V0p6ou89uFjcfnRx7O4s3gOXTCm+P+p7D96qvpPRsPdG1/EVjzlfvUaO/ud1cvyK13qNeiWWu/p+j2e19T5kxSsAZIwVrwCQMZI8AGSMJA8AGSPJA0DGSPIAkDGSPABkjCQPABkjyQNAxv4f3wfeDx/VOmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8672d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)     ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scatter函数用于绘制散点图。\n",
    "matplotlib.pyplot.scatter(x,y,s=20,c='b',maker='o',cmpa=None,norm=None,vmin=None,vax=None,alpha=None,linewidths=None,verts=None,hole=None)\n",
    "函数中各个参数介绍:\n",
    "x,y是相同长度的数组。\n",
    "s可以是标量，或者与x,y长度相同的数组，表明散点的大小。默认20\n",
    "c，即color，是点的颜色。颜色参数如下：b-blue   c-cyan  g-greeen  k-black  m-magenta  r-red  w-white  y-yellow\n",
    "marker 是散点的形状。其属性较多，. -点  o-圆圈  ，-像素  v-倒三角  *-星星"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(theta,x_b,y):\n",
    "    try:\n",
    "        return  ((y-x_b.dot(theta))**2)/len(x_b)                         \n",
    "#np.dot(A, B)：对于二维矩阵，计算真正意义上的矩阵乘积，同线性代数中矩阵乘法的定义。对于一维矩阵，计算两者的内积\n",
    "    except:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJ(theta,x_b,y):      #dot函数矩阵乘\n",
    "    res=np.empty(len(theta))  \n",
    "    #empty一样,它所常见的数组内所有元素均为空\n",
    "    res[0]=np.sum(x_b.dot(theta)-y)\n",
    "    for i in range(1,len(theta)):\n",
    "        res[i]=(x_b.dot(theta)-y).dot(x_b[:,1])\n",
    "    return res*2/len(x_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x_b ,y , initial_theta , eta, n_iters=1e4):\n",
    "    theta=initial_theta \n",
    "    i_iter=0\n",
    "    esplion=1e-8\n",
    "    \n",
    "    while i_iter<n_iters:\n",
    "        gradient=dJ(theta,x_b,y)\n",
    "        last_theta=theta\n",
    "        theta=theta-eta * gradient  ###迭代 让theta每次都能向导数的负方向移一步\n",
    "\n",
    "        if(abs((J(last_theta,x_b,y)-J(theta,x_b,y)).any())<esplion):\n",
    "              break\n",
    "        i_iter+=1\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b=np.hstack([np.ones((len(x),1)),x.reshape(-1,1)])\n",
    "initial_theta=np.zeros(x_b.shape[1])\n",
    "eta=0.01\n",
    "\n",
    "theta=gradient_descent(x_b, y, initial_theta, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy对逻辑表达式判别不清楚，它可以返回False如果等号两边两个式子是数值相等，也可以返回True因为等号两边两个式子是逻辑相等。它觉得这是模棱两可的，因此放弃做判断，统一用a.any()进行或比较，或a.all()进行与比较。可以从下面例子体会一下。\n",
    "\n",
    "import numpy as numpy\n",
    "\n",
    "a=np.zeros(3)\n",
    "\n",
    "a[0]=0; a[1]=1; a[2]=2\n",
    "\n",
    "print (a-[0,1,2]).any()\t#[0,0,0] False\n",
    "\n",
    "print (a-[0,1,2]).all()\t#[0,0,0] False\n",
    "\n",
    "print (a-[1,2,3]).any() #[-1,-1,-1] True\n",
    "\n",
    "print (a-[1,2,3]).all() #[-1,-1,-1] True\n",
    "\n",
    "print (a-[0,2,3]).any() #[0,-1,-1] True\n",
    "\n",
    "print (a-[0,2,3]).all() #[0,-1,-1] False\n",
    "\n",
    "numpy-array数组进行(a-b)比较时，True表示不同，False表示相同\n",
    "\n",
    "部分元素相等，.all()返False（一帮情况下不希望出现），.any()返回True; 所有元素都相等，二者均返回False\n",
    "\n",
    "因此最好使用.any()比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.00361994, 3.09666675])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试封装我们的线性回归算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"F:/PYCode\")####假如模块搜索的路径\n",
    "from machine_learning.LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit_gradient(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.00361994, 3.09666675])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg._theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法的向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.model_selection import train_test_split\n",
    "from  sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "x= boston.data\n",
    "y = boston.target\n",
    "\n",
    "x1 = x[y<50.0]\n",
    "y1 = y[y<50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test=train_test_split(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40520e-01, 0.00000e+00, 1.05900e+01, 0.00000e+00, 4.89000e-01,\n",
       "        6.37500e+00, 3.23000e+01, 3.94540e+00, 4.00000e+00, 2.77000e+02,\n",
       "        1.86000e+01, 3.85810e+02, 9.38000e+00],\n",
       "       [8.87300e-02, 2.10000e+01, 5.64000e+00, 0.00000e+00, 4.39000e-01,\n",
       "        5.96300e+00, 4.57000e+01, 6.81470e+00, 4.00000e+00, 2.43000e+02,\n",
       "        1.68000e+01, 3.95560e+02, 1.34500e+01],\n",
       "       [4.55587e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 7.18000e-01,\n",
       "        3.56100e+00, 8.79000e+01, 1.61320e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.54700e+02, 7.12000e+00],\n",
       "       [1.42310e-01, 0.00000e+00, 1.00100e+01, 0.00000e+00, 5.47000e-01,\n",
       "        6.25400e+00, 8.42000e+01, 2.25650e+00, 6.00000e+00, 4.32000e+02,\n",
       "        1.78000e+01, 3.88740e+02, 1.04500e+01],\n",
       "       [3.61500e-02, 8.00000e+01, 4.95000e+00, 0.00000e+00, 4.11000e-01,\n",
       "        6.63000e+00, 2.34000e+01, 5.11670e+00, 4.00000e+00, 2.45000e+02,\n",
       "        1.92000e+01, 3.96900e+02, 4.70000e+00],\n",
       "       [4.15292e+01, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.93000e-01,\n",
       "        5.53100e+00, 8.54000e+01, 1.60740e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.29460e+02, 2.73800e+01],\n",
       "       [7.24400e-02, 6.00000e+01, 1.69000e+00, 0.00000e+00, 4.11000e-01,\n",
       "        5.88400e+00, 1.85000e+01, 1.07103e+01, 4.00000e+00, 4.11000e+02,\n",
       "        1.83000e+01, 3.92330e+02, 7.79000e+00],\n",
       "       [8.98296e+00, 0.00000e+00, 1.81000e+01, 1.00000e+00, 7.70000e-01,\n",
       "        6.21200e+00, 9.74000e+01, 2.12220e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.77730e+02, 1.76000e+01],\n",
       "       [1.49320e-01, 2.50000e+01, 5.13000e+00, 0.00000e+00, 4.53000e-01,\n",
       "        5.74100e+00, 6.62000e+01, 7.22540e+00, 8.00000e+00, 2.84000e+02,\n",
       "        1.97000e+01, 3.95110e+02, 1.31500e+01],\n",
       "       [4.02020e-01, 0.00000e+00, 9.90000e+00, 0.00000e+00, 5.44000e-01,\n",
       "        6.38200e+00, 6.72000e+01, 3.53250e+00, 4.00000e+00, 3.04000e+02,\n",
       "        1.84000e+01, 3.95210e+02, 1.03600e+01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin.fit_gradient(x_train,y_train,eta=0.000001,n_iters = 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260547504710999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42886904, -0.09645924,  0.05396392, -0.09764766,  0.07749642,\n",
       "        0.2013657 ,  3.92855009,  0.01590937, -0.32823714,  0.10268746,\n",
       "       -0.00745236, -0.04205977,  0.01580074, -0.41044923])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin._theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法和数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand =  StandardScaler()\n",
    "stand.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stand = stand.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 383 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lin3.fit_gradient(x_train_stand,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_stand = stand.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7082750164666909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin3.score(x_test_stand, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降法的优势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m =1000\n",
    "n =5000\n",
    "from machine_learning.LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_x =np.random.normal(size=(m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_theta = np.random.uniform(0.0,100.0,size=n+1)\n",
    "big_y = big_x.dot(true_theta[1:])+true_theta[0]+np.random.normal(0., 10.,size=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_regl = LinearRegression()\n",
    "%time big_regl.fit_normal(big_x,big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_r = LinearRegression()\n",
    "%time big_r.fit_gradient(big_x,big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
